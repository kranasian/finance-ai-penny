from google import genai
from google.genai import types
import os
import json
from typing import Optional
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

SYSTEM_PROMPT = """You are a checker verifying goal agent optimizer outputs against rules.

## Input:
- **EVAL_INPUT**: Last User Request (user's last message), Previous Conversation (exchanges to contextualize Last User Request)
- **GENERATED_CODE**: Python code generated by the goal agent optimizer (string)
- **EXECUTION_RESULT**: Full execution log from running the generated code (string). Contains function calls, their parameters, return values, and final result.
- **PAST_REVIEW_OUTCOMES**: Array of past reviews, each with `generated_code`, `execution_result`, `good_copy`, `info_correct`, `eval_text`

## Output:
Only review the generated code and execution results. The inputs of each tool are out of scope.

JSON: `{"good_copy": boolean, "info_correct": boolean, "eval_text": string}`
- `good_copy`: **(CODE QUALITY ONLY)** True if GENERATED_CODE perfectly follows all code generation rules from the "Rules" section.
- `info_correct`: **(EXECUTION RESULT ONLY)** True if EXECUTION_RESULT shows that execution completed successfully and appropriately addressed the Last User Request.
- `eval_text`: Required if either boolean is False. Explains why without referring to the guidelines as "Rule 1", "Rule 2", etc. Be specific and concise (less than 25 words).

## Critical Priority: Learn from PAST_REVIEW_OUTCOMES
**MANDATORY**: If PAST_REVIEW_OUTCOMES flags issues that still exist in GENERATED_CODE or EXECUTION_RESULT, mark as incorrect.
- Extract all issues from past `eval_text` fields
- Check if GENERATED_CODE or EXECUTION_RESULT repeats the same mistakes
- If past reviews say "contains unnecessary chaining" and it's still there → mark `good_copy: False`
- If past reviews say "missing error handling" and it's still missing → mark `good_copy: False`
- If past reviews say "execution failed" and execution still fails → mark `info_correct: False`

## Rules

### Code Structure (`good_copy` ONLY)
1. **Function Definition**: Must define `execute_plan()` function that takes no arguments and returns `tuple[bool, str]`.
2. **Only Skill Functions**: Code should only use the available skill functions:
   - `lookup_user_accounts_transactions_income_and_spending_patterns(lookup_request: str, input_info: str = None) -> tuple[bool, str]`
   - `create_budget_or_goal(creation_request: str, input_info: str = None) -> tuple[bool, str]`
   - `research_and_strategize_financial_outcomes(strategize_request: str, input_info: str = None) -> tuple[bool, str]`
   - `update_transaction_category_or_create_category_rules(categorize_request: str, input_info: str = None) -> tuple[bool, str]`
3. **No Other Python Functions**: Should not use other Python functions beyond skill functions, conditional operations, and string concatenations. No imports, no datetime operations, no other libraries.
4. **Error Handling**: Should check `success` from each skill function call and return early if `success` is False. Must not proceed to next step if previous step failed.

### Task Prioritization (`good_copy` ONLY)
1. **Always Assume Financial Goal Context**: Interpret Last User Request and Previous Conversation as exchanges that followed the prompt "What are your financial goals?".
2. **Prioritize Last User Request**: The code must directly address the Last User Request. Steps should only be for achieving the Last User Request. Avoid adding steps related to past topics unless absolutely necessary.
3. **Use Previous Conversation Appropriately**:
   - For all skill requests, must thoroughly analyze Previous Conversation to gain accurate understanding of user's intent and ensure request parameters are comprehensive and contextually relevant.
   - If Previous Conversation contains the EXACT, COMPLETE information needed (e.g., current spending amount), it can be incorporated directly without a lookup step.
4. **Extract Key Information**: Vigilantly identify and extract critical details from the user's request, such as amounts and timelines.
5. **Handle Multiple Goals Sequentially**: Address multiple goals one by one in the plan.

### Goal-Oriented Flow (`good_copy` ONLY)
1. **Step 1: Gather Data (If Necessary)**: For goal-oriented requests, gather data if needed:
   - Data on user's finances: use `lookup_user_accounts_transactions_income_and_spending_patterns`
   - Data outside user's finances (requiring research): use `research_and_strategize_financial_outcomes`
   - If Previous Conversation contains the EXACT, COMPLETE information needed, this step can be skipped
2. **Step 2: Strategize (If Complex)**: If the goal is complex (e.g., retirement planning, college savings, debt paydown strategy), use `research_and_strategize_financial_outcomes` to create a clear strategy. Simple savings goals for a specific item do not usually require this step.
3. **Step 3: Create Goal (Default Final Step)**: This is the default final step for goal-oriented requests. Use all gathered information and strategy to make a precise `creation_request` with `create_budget_or_goal`.

### Information-Seeking Flow (`good_copy` ONLY)
1. **Question-Based Requests**: If the user asks a question, the plan should consist of the necessary `lookup` or `research` skills to acquire the information.
2. **Return Information Directly**: The plan's final output should be the information itself. Do NOT use `create_budget_or_goal` for information-seeking requests.
3. **Use Appropriate Skill**: 
   - Use `lookup_user_accounts_transactions_income_and_spending_patterns` for questions about user's own financial data
   - Use `research_and_strategize_financial_outcomes` for questions requiring external research or general financial advice

### Categorization Flow (`good_copy` ONLY)
1. **Must Use Categorization Skill**: If the user wants to categorize transactions or create categorization rules, the plan MUST use the `update_transaction_category_or_create_category_rules` skill.
2. **Category Rules**: If user hints at doing this in the future as well, specify that a category rule needs to be created on top of updating transaction categories.

### Skill Usage Guidelines (`good_copy` ONLY)
1. **create_budget_or_goal Usage**: 
   - This is the default final step for goal-oriented requests
   - Should NOT be used for categorization tasks
   - Should NOT be used for information-seeking questions
   - Should be used when user states a financial goal (explicit or implicit)
2. **research_and_strategize_financial_outcomes Usage**:
   - Use for research (e.g., "average dining out for a couple in Chicago", "estimated cost of a flight from Manila to Greece")
   - Use for creating complex financial plans requiring simulation or forecasting beyond simple data lookups
   - Do NOT use to analyze the user's own data; use `lookup_user_accounts_transactions_income_and_spending_patterns` for that
3. **lookup_user_accounts_transactions_income_and_spending_patterns Usage**:
   - Use for all questions about user's accounts, transactions, income, spending, subscriptions
   - Use for comparisons, summaries, calculations, and assessments on user data
   - Use for forecasted income and spending
   - Can be skipped if Previous Conversation contains the EXACT, COMPLETE information needed

### Request Parameter Quality (`good_copy` ONLY)
1. **Comprehensive Request Parameters**: Request parameters (e.g., `lookup_request`, `creation_request`, `strategize_request`) must effectively incorporate relevant information from Previous Conversation and, when available, the `input_info` to accurately address the Last User Request.
2. **Natural Language**: Request parameters must be written in natural language and be descriptive enough to capture the user's intent comprehensively.
3. **Context Incorporation**: When `input_info` is available, must incorporate it concisely into subsequent skill function calls. The `input_info` should refine and enhance the request parameter.
4. **Multiple Requests Support**: All skill functions can accept multiple requests written as multiple sentences in their request parameters. Use this capability when appropriate.

### Execution Result (`info_correct` ONLY)
1. **Execution Success**: EXECUTION_RESULT should show that all function calls completed successfully (returned `True` for success). If any function call failed, execution should have stopped and returned early.
2. **Final Output Relevance**: The final output from `execute_plan()` should directly address the Last User Request. Should not include unnecessary information or omit critical information.
3. **Function Call Appropriateness**: All function calls in EXECUTION_RESULT should match what the GENERATED_CODE intended. Check that function names match, request parameters are appropriate and contextually relevant, and `input_info` is properly passed between functions when chaining.
4. **Error Handling in Execution**: If execution failed, the output should contain meaningful error information or indicate what additional information is needed. The code should have handled errors gracefully.

## Verification Steps

1. **Check PAST_REVIEW_OUTCOMES first**: Extract all flagged issues. If GENERATED_CODE or EXECUTION_RESULT repeats them → mark False
2. **Verify good_copy**: Does GENERATED_CODE follow the code structure, task prioritization, efficiency, and request parameter quality guidelines listed above?
3. **Verify info_correct**: Does EXECUTION_RESULT show successful execution that appropriately addressed the Last User Request?
4. **Write eval_text**: If good_copy and/or info_correct is False, explain the specific issues.
--
"""

class CheckGoalAgentOptimizer:
  """Handles all Gemini API interactions for checking goal agent optimizer outputs against rules"""
  
  def __init__(self, model_name="gemini-3-flash-preview"):
    """Initialize the Gemini agent with API configuration for checking goal agent optimizer evaluations"""
    # API Configuration
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
      raise ValueError("GEMINI_API_KEY environment variable is not set. Please set it in your .env file or environment.")
    self.client = genai.Client(api_key=api_key)
    
    # Model Configuration
    self.thinking_budget = 8196
    self.model_name = model_name
    
    # Generation Configuration Constants
    self.temperature = 0.6
    self.top_p = 0.95
    self.max_output_tokens = 8192
    
    # Safety Settings
    self.safety_settings = [
      types.SafetySetting(category="HARM_CATEGORY_HATE_SPEECH", threshold="OFF"),
      types.SafetySetting(category="HARM_CATEGORY_DANGEROUS_CONTENT", threshold="OFF"),
      types.SafetySetting(category="HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold="OFF"),
      types.SafetySetting(category="HARM_CATEGORY_HARASSMENT", threshold="OFF")
    ]
    
    # System Prompt
    self.system_prompt = SYSTEM_PROMPT

  
  def generate_response(self, request_text) -> dict:
    """
    Generate a response using Gemini API for checking goal agent optimizer evaluations.
    
    Args:
      request_text: Formatted request text containing EVAL_INPUT, GENERATED_CODE, EXECUTION_RESULT, and optional PAST_REVIEW_OUTCOMES
      
    Returns:
      Dictionary with good_copy, info_correct, and eval_text keys
    """
    # Create content and configuration
    contents = [types.Content(role="user", parts=[request_text])]
    
    generate_content_config = types.GenerateContentConfig(
      temperature=self.temperature,
      top_p=self.top_p,
      max_output_tokens=self.max_output_tokens,
      safety_settings=self.safety_settings,
      system_instruction=[types.Part.from_text(text=self.system_prompt)],
      thinking_config=types.ThinkingConfig(thinking_budget=self.thinking_budget),
    )

    # Generate response
    output_text = ""
    for chunk in self.client.models.generate_content_stream(
      model=self.model_name,
      contents=contents,
      config=generate_content_config,
    ):
      if chunk.text is not None:
        output_text += chunk.text
    
    # Check if response is empty
    if not output_text or not output_text.strip():
      raise ValueError(f"Empty response from model. Check API key and model availability.")
    
    # Parse JSON response
    try:
      # Remove markdown code blocks if present
      if "```json" in output_text:
        json_start = output_text.find("```json") + 7
        json_end = output_text.find("```", json_start)
        if json_end != -1:
          output_text = output_text[json_start:json_end].strip()
      elif "```" in output_text:
        # Try to find JSON in code blocks
        json_start = output_text.find("```") + 3
        json_end = output_text.find("```", json_start)
        if json_end != -1:
          output_text = output_text[json_start:json_end].strip()
      
      # Try parsing the whole response first
      parsed = json.loads(output_text.strip())
      
      # Ensure it has the required keys
      if not isinstance(parsed, dict):
        raise ValueError(f"Expected dict, got {type(parsed)}")
      
      if "good_copy" not in parsed or "info_correct" not in parsed:
        raise ValueError(f"Missing required keys: good_copy, info_correct")
      
      return parsed
    except json.JSONDecodeError as e:
      raise ValueError(f"Failed to parse JSON response: {e}\nResponse length: {len(output_text)}\nResponse preview: {output_text[:500]}")


def _run_test_with_logging(last_user_request: str, previous_conversation: Optional[str] = None, generated_code: str = "", execution_result: str = "", past_review_outcomes: Optional[list] = None, checker: Optional[CheckGoalAgentOptimizer] = None):
  """
  Internal helper function that runs a test with consistent logging.
  
  Args:
    last_user_request: The user's most recent request (string)
    previous_conversation: The conversation history before the last user request (string)
    generated_code: The Python code generated by the goal agent optimizer (string)
    execution_result: Full execution log from running the generated code (string)
    past_review_outcomes: Optional array of past review outcomes, each containing `generated_code`, `execution_result`, `good_copy`, `info_correct`, and `eval_text`
    checker: Optional CheckGoalAgentOptimizer instance. If None, creates a new one.
    
  Returns:
    Dictionary with good_copy, info_correct, and eval_text keys, or None if error occurred
  """
  if checker is None:
    checker = CheckGoalAgentOptimizer()
  
  # Print the exact input that will be passed to the LLM
  past_review_section = ""
  if past_review_outcomes:
    # Loop through past_review_outcomes and add each to the past_review_section
    for index, past_review_outcome in enumerate(past_review_outcomes):
      past_review_section += f"""<PAST_REVIEW_OUTCOME_{index + 1}>

## Generated Code for #{index + 1}

```python
{past_review_outcome['generated_code']}
```

## Execution Result for #{index + 1}

{past_review_outcome['execution_result']}

## Evaluation Output for #{index + 1}

```json
{json.dumps(past_review_outcome['output'], indent=2)}
```

</PAST_REVIEW_OUTCOME_{index + 1}>

"""
  
  if previous_conversation:
    previous_conversation_section = f"""**Previous Conversation**:
{previous_conversation}"""
  else:
    previous_conversation_section = """**Previous Conversation**:
None"""

  request_str = f"""<EVAL_INPUT>
**Last User Request**: {last_user_request}
{previous_conversation_section}
</EVAL_INPUT>

<GENERATED_CODE>

```python
{generated_code}
```

</GENERATED_CODE>

<EXECUTION_RESULT>

{execution_result}

</EXECUTION_RESULT>

{past_review_section}

Output:"""
  
  print("=" * 80)
  print("LLM INPUT:")
  print("=" * 80)
  print(request_str)
  print("=" * 80)
  print()
  
  try:
    result = checker.generate_response(types.Part.from_text(text=request_str))
    
    print("=" * 80)
    print("LLM OUTPUT:")
    print("=" * 80)
    print(json.dumps(result, indent=2))
    print("=" * 80)
    print()
    
    return result
  except Exception as e:
    print(f"ERROR: {type(e).__name__}: {str(e)}")
    import traceback
    print(traceback.format_exc())
    print("=" * 80)
    print()
    return None


def test_vacation_fund_goal_with_error_handling(checker: CheckGoalAgentOptimizer = None):
  """
  Test method for vacation fund goal creation with error handling issues.
  
  Args:
    checker: Optional CheckGoalAgentOptimizer instance. If None, creates a new one.
    
  Returns:
    Dictionary with good_copy, info_correct, and eval_text keys
  """
  last_user_request = "Create a vacation fund goal of $3,000 for a trip to Japan next October."
  previous_conversation = None

  generated_code = """def execute_plan() -> tuple[bool, str]:
    # Step 1: Gather Data (Lookup current finances to assess feasibility for saving $3,000 by next October)
    success, lookup_result = lookup_user_accounts_transactions_income_and_spending_patterns(
        lookup_request="Analyze current savings capacity and recurring expenses to determine the required monthly contribution needed to save $3,000 for a vacation trip to Japan by next October."
    )
    if not success:
        # If lookup fails or needs more context, we pass the result to the next step, 
        # which might be creation or strategy, or it might prompt the user for more info if creation is called next.
        pass
    # Step 2 & 3: Strategize (if needed) and Create Goal
    # For a specific savings target, we often go straight to creation, letting the creation skill prompt for missing details 
    # (like current savings rate or exact current date if needed for calculation) if the lookup wasn't enough.
    
    success, creation_result = create_budget_or_goal(
        creation_request="Create a dedicated vacation fund goal of $3,000 for a trip to Japan scheduled for next October.",
        input_info=lookup_result
    )
    if not success:
        return False, creation_result
    
    return True, creation_result
"""

  execution_result = """lookup_user_accounts_transactions_income_and_spending_patterns:
  lookup_request: Analyze current savings capacity and recurring expenses to determine the required monthly contribution needed to save $3,000 for a vacation trip to Japan by next October.
  input_info: None
  return: (False, "Error calling P:Func:LookupUserData template: 'NoneType' object has no attribute 'cursor'")
create_budget_or_goal:
  creation_request: Create a dedicated vacation fund goal of $3,000 for a trip to Japan scheduled for next October.
  input_info: Error calling P:Func:LookupUserData template: 'NoneType' object has no attribute 'cursor'
  return: (False, "Error calling P:Func:CreateBudgetOrGoalOrReminder template: 'NoneType' object has no attribute 'cursor'")
execute_plan:
False
Error calling P:Func:CreateBudgetOrGoalOrReminder template: 'NoneType' object has no attribute 'cursor'
"""

  return _run_test_with_logging(last_user_request, previous_conversation, generated_code, execution_result, None, checker)


def main(batch: int = 1):
  """
  Main function to test the checker optimizer
  
  Args:
    batch: Batch number (1, 2, 3, or 4) to determine which tests to run
  """
  print("Testing CheckGoalAgentOptimizer\n")
  
  if batch == 1:
    # Primary test case: Vacation fund goal with error handling issues
    print("Test 1: Vacation fund goal with error handling issues")
    print("-" * 80)
    test_vacation_fund_goal_with_error_handling()
    print("\n")
  # elif batch == 2:
  #   # Incorrect efficiency cases
  #   print("Test 1: Incorrect unnecessary chaining")
  #   print("-" * 80)
  #   test_incorrect_unnecessary_chaining()
  #   print("\n")
    
  #   print("Test 2: Incorrect missing lookup for data request")
  #   print("-" * 80)
  #   test_incorrect_missing_lookup_for_data_request()
  #   print("\n")
  #   # Incorrect code structure cases
  #   print("Test 1: Incorrect missing error handling")
  #   print("-" * 80)
  #   test_incorrect_missing_error_handling()
  #   print("\n")
  # elif batch == 3:
  #   print("Test 2: Past review outcomes issue persists")
  #   print("-" * 80)
  #   test_past_review_outcomes_issue_persists()
  #   print("\n")
  else:
    raise ValueError("batch must be 1, 2, 3, or 4")
  
  print("All tests completed!")


if __name__ == "__main__":
  import argparse
  parser = argparse.ArgumentParser(description='Run tests in batches')
  parser.add_argument('--batch', type=int, default=1, choices=[1, 2, 3, 4],
                      help='Batch number to run (1, 2, 3, or 4)')
  args = parser.parse_args()
  main(batch=args.batch)

