from google import genai
from google.genai import types
import os
import json
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

SYSTEM_PROMPT = """You are a checker verifying goal agent optimizer outputs against rules.

## Input:
- **LAST_USER_REQUEST**: The user's most recent request (string)
- **PREVIOUS_CONVERSATION**: The conversation history before the last user request (string)
- **GENERATED_CODE**: Python code generated by the goal agent optimizer (string)
- **EXECUTION_RESULT**: Full execution log from running the generated code (string). Contains function calls, their parameters, return values, and final result.
- **PAST_REVIEW_OUTCOMES**: Array of past reviews, each with `generated_code`, `execution_result`, `code_correct`, `execution_correct`, `eval_text`

## Output:
JSON: `{"code_correct": boolean, "execution_correct": boolean, "eval_text": string}`
- `code_correct`: **(CODE QUALITY ONLY)** True if GENERATED_CODE perfectly follows all code generation rules from the "Rules" section. This includes function structure, skill usage, efficiency rules, request parameter quality, and code correctness.
- `execution_correct`: **(EXECUTION RESULT ONLY)** True if EXECUTION_RESULT shows that execution completed successfully and appropriately addressed the LAST_USER_REQUEST. Check if all function calls succeeded, if the final output addresses the user request, and if the execution flow matches what the code intended.
- `eval_text`: Required if either boolean is False. Explains why. Be specific. Reference the exact rule that was broken.

## Critical Priority: Strict Compliance (Recall over Precision)
- **Recall over Precision**: It is better to mark an issue as Incorrect (False) if you are unsure, than to let a potential issue pass as Correct (True).
- Mark `code_correct` or `execution_correct` as False if there is **ANY potential violation** of the rules below.
- False positives (flagging correct content as issues) are preferred over false negatives (missing actual issues).

## Critical Priority: Learn from PAST_REVIEW_OUTCOMES
**MANDATORY**: If PAST_REVIEW_OUTCOMES flags issues that still exist in GENERATED_CODE or EXECUTION_RESULT, mark as incorrect.
- Extract all issues from past `eval_text` fields
- Check if GENERATED_CODE or EXECUTION_RESULT repeats the same mistakes
- If a past review flagged a specific pattern (e.g., unnecessary chaining, missing lookup), and the current code shows the same pattern, mark as False.

## Rules

### Part 1: Code Structure Rules (`code_correct` ONLY)
1. **Function Definition**: Must define `execute_plan()` function that takes no arguments and returns `tuple[bool, str]`.
2. **Function Return Type**: Must explicitly return `tuple[bool, str]` where first element is success boolean and second is output string.
3. **Only Skill Functions**: Code should only use the available skill functions:
   - `lookup_user_accounts_transactions_income_and_spending_patterns(lookup_request: str, input_info: str = None) -> tuple[bool, str]`
   - `create_budget_or_goal(creation_request: str, input_info: str = None) -> tuple[bool, str]`
   - `research_and_strategize_financial_outcomes(strategize_request: str, input_info: str = None) -> tuple[bool, str]`
4. **No Other Python Functions**: Should not use other Python functions beyond skill functions, conditional operations, and string concatenations. No imports, no datetime operations, no other libraries.
5. **Error Handling**: Should check `success` from each skill function call and return early if `success` is False. Must not proceed to next step if previous step failed.

### Part 2: Task Prioritization Rules (`code_correct` ONLY)
1. **Prioritize Last User Request**: The code must directly address the LAST_USER_REQUEST. Steps should only be for achieving the LAST_USER_REQUEST. Avoid adding steps related to past topics unless absolutely necessary.
2. **Use Previous Conversation Appropriately**:
   - If LAST_USER_REQUEST is a follow-up (e.g., "yes, do that"), must use PREVIOUS_CONVERSATION context.
   - If LAST_USER_REQUEST is vague (e.g., "what about the other thing?"), must use PREVIOUS_CONVERSATION context.
   - **CRITICAL**: For all skill requests, must thoroughly analyze PREVIOUS_CONVERSATION to gain accurate understanding of user's intent and ensure request parameters are comprehensive and contextually relevant.
   - **If LAST_USER_REQUEST is a new, general question (e.g., "how's my accounts doing?"), DO NOT use specific details from PREVIOUS_CONVERSATION in the plan.**

### Part 3: Efficiency Rules - Lookup Priority (`code_correct` ONLY)
1. **Prioritize Lookup for ALL Data-Related Inquiries**: If LAST_USER_REQUEST requires ANY user account, transaction, income, or spending data, or asks for comparisons, summaries, or calculations based on this user data, MUST call `lookup_user_accounts_transactions_income_and_spending_patterns` FIRST.
2. **Always Start with Lookup for Data Requests**: Even if PREVIOUS_CONVERSATION contains some financial information, if the request needs current/fresh user data, involves a comparison (e.g., "compare X to Y"), a summary (e.g., "summarize my spending"), or a calculation (e.g., "calculate my savings rate") on user data, MUST call lookup FIRST.
3. **Lookup is Primary Data Source**: For any question about user's financial status, accounts, transactions, spending, income, or requests involving comparisons, summaries, or calculations of this user data, ALWAYS start with lookup. It is designed to provide the most current and comprehensive user data.
4. **Skip Lookup Only in Rare Cases**: Only skip lookup if PREVIOUS_CONVERSATION contains the EXACT, COMPLETE user data needed AND the request does not imply needing current user data, comparison, summary, or calculation, AND the request is about a specific past event already discussed.

### Part 4: Efficiency Rules - Avoid Unnecessary Chaining (`code_correct` ONLY)
1. **CRITICAL DECISION RULE**: After calling lookup, evaluate if its output directly and completely answers the LAST_USER_REQUEST. If yes, return it immediately - do NOT add `research_and_strategize_financial_outcomes`.
2. **Do Not Chain Unnecessarily**: If `lookup_user_accounts_transactions_income_and_spending_patterns` alone can fully answer the LAST_USER_REQUEST (especially for direct user data retrieval, comparisons, summaries, or calculations on user data), return it directly - do NOT chain with `research_and_strategize_financial_outcomes`.
3. **Simple Informational Questions**: If LAST_USER_REQUEST is primarily an information question, a comparison, a summary, or a direct calculation on user data (e.g., "how's my accounts doing?", "what's my balance?", "compare my spending this month to last month", "summarize my investment performance", "calculate my net worth"), `lookup_user_accounts_transactions_income_and_spending_patterns` alone is almost always sufficient - do NOT chain with `research_and_strategize_financial_outcomes`.
4. **Use Strategize Only When Explicitly Needed**: Only use `research_and_strategize_financial_outcomes` if the request explicitly requires:
   - Complex analysis or long-term planning
   - Multi-step strategy
   - Future forecasting or what-if scenarios
   - Research or general advice (e.g., "what's the best plan to...", "how should I...", "create a plan to...", "what are the best ways to save?")
   - Financial calculations requiring modeling (e.g., "when can I retire")
5. **Avoid Adding Strategize "Just to Be Thorough"**: If lookup provides sufficient information to answer the question, return it directly without additional skills. Do not add strategize for completeness.

### Part 5: Efficiency Rules - Goal/Budget Creation (`code_correct` ONLY)
1. **Avoid Unnecessary create_budget_or_goal**: If LAST_USER_REQUEST is a question (e.g., "what are the steps to save money?"), avoid using `create_budget_or_goal`.
2. **Only Create When Explicitly Asked**: Only use `create_budget_or_goal` if user explicitly asks to *create*, *set up*, *establish*, or *track* a budget or goal.
3. **For Goal-Setting or Planning Requests**: 
   - Always perform `lookup_user_accounts_transactions_income_and_spending_patterns` first to understand user's current financial situation.
   - Then, use `research_and_strategize_financial_outcomes` to develop the plan or provide tips, incorporating the `input_info` from the lookup.
   - Avoid calling `create_budget_or_goal` unless the user explicitly asks to *create* a budget or goal.

### Part 6: Request Parameter Quality Rules (`code_correct` ONLY)
1. **Comprehensive Request Parameters**: Request parameters (e.g., `lookup_request`, `creation_request`, `strategize_request`) must effectively incorporate relevant information from PREVIOUS_CONVERSATION and, when available, the `input_info` to accurately address the LAST_USER_REQUEST.
2. **Natural Language**: Request parameters must be written in natural language and be descriptive enough to capture the user's intent comprehensively.
3. **Context Incorporation**: When `input_info` is available, must incorporate it concisely into subsequent skill function calls. The `input_info` should refine and enhance the request parameter.
4. **Multiple Requests Support**: All skill functions can accept multiple requests written as multiple sentences in their request parameters. Use this capability when appropriate.

### Part 7: Execution Result Rules (`execution_correct` ONLY)
1. **Execution Success**: EXECUTION_RESULT should show that all function calls completed successfully (returned `True` for success). If any function call failed, execution should have stopped and returned early.
2. **Final Output Relevance**: The final output from `execute_plan()` should directly address the LAST_USER_REQUEST. Should not include unnecessary information or omit critical information.
3. **Function Call Appropriateness**: All function calls in EXECUTION_RESULT should match what the GENERATED_CODE intended. Check that:
   - Function names match
   - Request parameters are appropriate and contextually relevant
   - `input_info` is properly passed between functions when chaining
4. **Error Handling in Execution**: If execution failed, the output should contain meaningful error information or indicate what additional information is needed. The code should have handled errors gracefully.

## Verification Steps

1. **Check PAST_REVIEW_OUTCOMES first**: Extract all flagged issues from past `eval_text` fields. If GENERATED_CODE or EXECUTION_RESULT repeats them -> mark False.
2. **Verify Code Correctness (`code_correct`)**: 
   - Check GENERATED_CODE against LAST_USER_REQUEST and PREVIOUS_CONVERSATION for violations of:
     - Code Structure Rules
     - Task Prioritization Rules
     - Efficiency Rules (Lookup Priority, Avoid Unnecessary Chaining, Goal/Budget Creation)
     - Request Parameter Quality Rules
3. **Verify Execution Correctness (`execution_correct`)**: 
   - Parse EXECUTION_RESULT to understand what actually happened during execution
   - Check if execution succeeded when it should have
   - Verify that the final output addresses LAST_USER_REQUEST
   - Check if function calls match the code's intent
4. **Write eval_text**: If any check fails, list the specific issues with clear references to the rule that was broken. Be specific about what was wrong and what should have been done instead.
"""

class CheckGoalAgentOptimizer:
  """Handles all Gemini API interactions for checking goal agent optimizer outputs against rules"""
  
  def __init__(self, model_name="gemini-3-flash-preview"):
    """Initialize the Gemini agent with API configuration for checking goal agent optimizer evaluations"""
    # API Configuration
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
      raise ValueError("GEMINI_API_KEY environment variable is not set. Please set it in your .env file or environment.")
    self.client = genai.Client(api_key=api_key)
    
    # Model Configuration
    self.thinking_budget = 8196
    self.model_name = model_name
    
    # Generation Configuration Constants
    self.temperature = 0.6
    self.top_p = 0.95
    self.max_output_tokens = 8192
    
    # Safety Settings
    self.safety_settings = [
      types.SafetySetting(category="HARM_CATEGORY_HATE_SPEECH", threshold="OFF"),
      types.SafetySetting(category="HARM_CATEGORY_DANGEROUS_CONTENT", threshold="OFF"),
      types.SafetySetting(category="HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold="OFF"),
      types.SafetySetting(category="HARM_CATEGORY_HARASSMENT", threshold="OFF")
    ]
    
    # System Prompt
    self.system_prompt = SYSTEM_PROMPT

  
  def generate_response(self, request_text) -> dict:
    """
    Generate a response using Gemini API for checking goal agent optimizer evaluations.
    
    Args:
      last_user_request: The user's most recent request (string)
      previous_conversation: The conversation history before the last user request (string)
      generated_code: The Python code generated by the goal agent optimizer (string)
      execution_result: Full execution log from running the generated code (string)
      past_review_outcomes: Optional array of past review outcomes, each containing `generated_code`, `execution_result`, `code_correct`, `execution_correct`, and `eval_text`
      
    Returns:
      Dictionary with code_correct, execution_correct, and eval_text keys
    """
    # Create content and configuration
    contents = [types.Content(role="user", parts=[request_text])]
    
    generate_content_config = types.GenerateContentConfig(
      temperature=self.temperature,
      top_p=self.top_p,
      max_output_tokens=self.max_output_tokens,
      safety_settings=self.safety_settings,
      system_instruction=[types.Part.from_text(text=self.system_prompt)],
      thinking_config=types.ThinkingConfig(thinking_budget=self.thinking_budget),
    )

    # Generate response
    output_text = ""
    for chunk in self.client.models.generate_content_stream(
      model=self.model_name,
      contents=contents,
      config=generate_content_config,
    ):
      if chunk.text is not None:
        output_text += chunk.text
    
    # Check if response is empty
    if not output_text or not output_text.strip():
      raise ValueError(f"Empty response from model. Check API key and model availability.")
    
    # Parse JSON response
    try:
      # Remove markdown code blocks if present
      if "```json" in output_text:
        json_start = output_text.find("```json") + 7
        json_end = output_text.find("```", json_start)
        if json_end != -1:
          output_text = output_text[json_start:json_end].strip()
      elif "```" in output_text:
        # Try to find JSON in code blocks
        json_start = output_text.find("```") + 3
        json_end = output_text.find("```", json_start)
        if json_end != -1:
          output_text = output_text[json_start:json_end].strip()
      
      # Try parsing the whole response first
      parsed = json.loads(output_text.strip())
      
      # Ensure it has the required keys
      if not isinstance(parsed, dict):
        raise ValueError(f"Expected dict, got {type(parsed)}")
      
      if "code_correct" not in parsed or "execution_correct" not in parsed:
        raise ValueError(f"Missing required keys: code_correct, execution_correct")
      
      return parsed
    except json.JSONDecodeError as e:
      raise ValueError(f"Failed to parse JSON response: {e}\nResponse length: {len(output_text)}\nResponse preview: {output_text[:500]}")


def _run_test_with_logging(last_user_request: str, previous_conversation: str, generated_code: str, execution_result: str, past_review_outcomes: list = None, checker: CheckGoalAgentOptimizer = None):
  """
  Internal helper function that runs a test with consistent logging.
  
  Args:
    last_user_request: The user's most recent request (string)
    previous_conversation: The conversation history before the last user request (string)
    generated_code: The Python code generated by the goal agent optimizer (string)
    execution_result: Full execution log from running the generated code (string)
    past_review_outcomes: Optional array of past review outcomes, each containing `generated_code`, `execution_result`, `code_correct`, `execution_correct`, and `eval_text`
    checker: Optional CheckGoalAgentOptimizer instance. If None, creates a new one.
    
  Returns:
    Dictionary with code_correct, execution_correct, and eval_text keys, or None if error occurred
  """
  if checker is None:
    checker = CheckGoalAgentOptimizer()
  
  # Print the exact input that will be passed to the LLM
  past_review_section = ""
  if past_review_outcomes:
    # Loop through past_review_outcomes and add each to the past_review_section
    for index, past_review_outcome in enumerate(past_review_outcomes):
      past_review_section += f"""<PAST_REVIEW_OUTCOME_{index + 1}>

## Generated Code for #{index + 1}

```python
{past_review_outcome['generated_code']}
```

## Execution Result for #{index + 1}

{past_review_outcome['execution_result']}

## Evaluation Output for #{index + 1}

```json
{json.dumps(past_review_outcome['output'], indent=2)}
```

</PAST_REVIEW_OUTCOME_{index + 1}>

"""
  
    previous_conversation_section = f"""
**Previous Conversation**:
{previous_conversation}""" if previous_conversation else ""

    request_str = f"""<EVAL_INPUT>
**Last User Request**: {last_user_request}{previous_conversation_section}
</EVAL_INPUT>

<GENERATED_CODE>

```python
{generated_code}
```

</GENERATED_CODE>

<EXECUTION_RESULT>

{execution_result}

</EXECUTION_RESULT>

{past_review_section}

Output:"""
  
  print("=" * 80)
  print("LLM INPUT:")
  print("=" * 80)
  print(request_str)
  print("=" * 80)
  print()
  
  try:
    result = checker.generate_response(types.Part.from_text(text=request_str))
    
    print("=" * 80)
    print("LLM OUTPUT:")
    print("=" * 80)
    print(json.dumps(result, indent=2))
    print("=" * 80)
    print()
    
    return result
  except Exception as e:
    print(f"ERROR: {type(e).__name__}: {str(e)}")
    import traceback
    print(traceback.format_exc())
    print("=" * 80)
    print()
    return None


def test_long_conversation_with_previous_conversation(checker: CheckGoalAgentOptimizer = None):
  """
  Test method for correct simple lookup case.
  
  Args:
    checker: Optional CheckGoalAgentOptimizer instance. If None, creates a new one.
    
  Returns:
    Dictionary with code_correct, execution_correct, and eval_text keys
  """
  last_user_request = "Create a budget cap of $800 for the final week of this month."
  previous_conversation = """User: How much did I spend in the last 7 days? I feel like I'm rushing to use money before the month is over.
Assistant: Your total spending over the past seven days was $955."""

  generated_code = """def execute_plan() -> tuple[bool, str]:
    # --- Goal 1: Create a budget cap of $800 for the final week of this month ---
    
    # Context from previous conversation: User spent $955 in the last 7 days (current month's end period).
    context_info_1 = "User recently spent $955 in the last 7 days."
    
    success, creation_result_1 = create_budget_or_goal(
        creation_request="Create a budget cap of $800 specifically for the final week of this month.",
        input_info=context_info_1
    )
    if not success:
        return False, f"Failed to set $800 budget: {creation_result_1}"

    # --- Goal 2: Analyze and create an action plan for improving spending vs. last month's final week ---
    
    # Step 2a: Lookup spending data for the final week of the previous month for comparison.
    lookup_request_2 = "Retrieve total spending data for the final week of the previous month to establish a baseline for comparison against the current $955 spending."
    
    success, lookup_result_2 = lookup_user_accounts_transactions_income_and_spending_patterns(
        lookup_request=lookup_request_2
    )
    if not success:
        return False, f"Could not retrieve last month's end-of-month spending data: {lookup_result_2}"

    # Step 2b: Strategize improvements based on the comparison data.
    strategize_request_2 = (
        f"Compare the spending from the final week of last month (data provided in input_info) "
        f"against the current period's spending of $955. Develop clear, actionable recommendations on how to improve spending for future end-of-month periods."
    )
    
    success, strategy_result_2 = research_and_strategize_financial_outcomes(
        strategize_request=strategize_request_2,
        input_info=lookup_result_2
    )
    if not success:
        return False, f"Failed to strategize spending improvements: {strategy_result_2}"

    # Step 2c: Create the improvement plan as a formal goal/action (Directive 2).
    creation_request_2 = "Create a formal goal based on the developed strategy to implement spending improvements for the end of the month."
    
    success, creation_result_2 = create_budget_or_goal(
        creation_request=creation_request_2,
        input_info=strategy_result_2
    )
    if not success:
        return False, f"Failed to create the spending improvement goal: {creation_result_2}"
"""

  # Execution Result
  execution_result = """create_budget_or_goal:
  creation_request: Create a budget cap of $800 specifically for the final week of this month.
  input_info: User recently spent $955 in the last 7 days.
  return: (True, "Successfully created 'Final Week Spending Cap ðŸ’¸' from 2025-12-14 to 2025-12-20 with target amount $800.00.")

lookup_user_accounts_transactions_income_and_spending_patterns:
  lookup_request: Retrieve total spending data for the final week of the previous month to establish a baseline for comparison against the current $955 spending.
  input_info: None
  return: (True, 'Baseline Spending (Week of 2025-11-30): $4394\nCurrent Spending: $955\nThe baseline was higher by $3439.')

research_and_strategize_financial_outcomes:
  strategize_request: Compare the spending from the final week of last month (data provided in input_info) against the current period's spending of $955. Develop clear, actionable recommendations on how to improve spending for future end-of-month periods.
  input_info: Baseline Spending (Week of 2025-11-30): $4394
Current Spending: $955
The baseline was higher by $3439.
  return: (True, '**Summary:** Your current spending of $955 is highly efficient compared to the $4,394 baseline. The strategy focuses on diagnosing and capping the unsustainable spending spike observed in the final week of last month.\n\n**Key Facts:**\n- **Baseline Spike:** $4,394 (Input: "Baseline Spending (Week of 2025-11-30): $4394")\n- **Current Efficiency:** $955 (Input: "Current Spending: $955")\n- **Variance:** The baseline was $3,439 higher (Input: "The baseline was higher by $3439.")\n\n**Strategy:**\n\n1. **Establish the New End-of-Month Cap:** Since the current period ($955) demonstrates high control, use this as your benchmark. Set a strict maximum spending limit of **$1,050** for any future final week (7-day period), ensuring you capture minimal necessary costs without repeating the $4,394 spike. (Calculation: $955 current spending * 1.10 buffer = $1,050.50).\n2. **Implement a "Discretionary Freeze":** If the $4,394 spike was due to non-essential purchases, institute a mandatory 7-day freeze on all discretionary spending (dining out, large retail) starting 5 days before the month closes, allowing only for pre-budgeted utility payments within the $1,050 cap.\n3. **Mandatory Root Cause Analysis:** Before the next month begins, review the specific transactions that comprised the $4,394 baseline to identify the exact nature of the overspend, preventing recurrence of that specific spending behavior. (Input: "The baseline was higher by $3439.")\n\n**Risks:** The strategy relies on the $955 period being representative of normal operational costs; if $955 was artificially low due to delayed billing, the $1,050 cap may be insufficient.')

create_budget_or_goal:
  creation_request: Create a formal goal based on the developed strategy to implement spending improvements for the end of the month.
  input_info: **Summary:** Your current spending of $955 is highly efficient compared to the $4,394 baseline. The strategy focuses on diagnosing and capping the unsustainable spending spike observed in the final week of last month.

**Key Facts:**
- **Baseline Spike:** $4,394 (Input: "Baseline Spending (Week of 2025-11-30): $4394")
- **Current Efficiency:** $955 (Input: "Current Spending: $955")
- **Variance:** The baseline was $3,439 higher (Input: "The baseline was higher by $3439.")

**Strategy:**

1. **Establish the New End-of-Month Cap:** Since the current period ($955) demonstrates high control, use this as your benchmark. Set a strict maximum spending limit of **$1,050** for any future final week (7-day period), ensuring you capture minimal necessary costs without repeating the $4,394 spike. (Calculation: $955 current spending * 1.10 buffer = $1,050.50).
2. **Implement a "Discretionary Freeze":** If the $4,394 spike was due to non-essential purchases, institute a mandatory 7-day freeze on all discretionary spending (dining out, large retail) starting 5 days before the month closes, allowing only for pre-budgeted utility payments within the $1,050 cap.
3. **Mandatory Root Cause Analysis:** Before the next month begins, review the specific transactions that comprised the $4,394 baseline to identify the exact nature of the overspend, preventing recurrence of that specific spending behavior. (Input: "The baseline was higher by $3439.")

**Risks:** The strategy relies on the $955 period being representative of normal operational costs; if $955 was artificially low due to delayed billing, the $1,050 cap may be insufficient.
  return: (True, "Successfully created 'End of Month Spending Cap' from 2025-12-01 to 2025-12-31 with target amount $1050.00.")


execute_plan:
True
Successfully executed both requests.
1. Budget Creation Result: Successfully created 'Final Week Spending Cap ðŸ’¸' from 2025-12-14 to 2025-12-20 with target amount $800.00.
2. Spending Improvement Plan Created: Successfully created 'End of Month Spending Cap' from 2025-12-01 to 2025-12-31 with target amount $1050.00.
"""

  generated_code_1 = """def execute_plan() -> tuple[bool, str]:
    # Step 1: Look up spending data, specifically comparing the last 7 days of the current month 
    # (for context on the requested budget) and the last 7 days of the previous month (for improvement comparison).
    success, lookup_result = lookup_user_accounts_transactions_income_and_spending_patterns(
        lookup_request="Analyze user spending data, comparing the last seven days of the current month against the last seven days of the previous month, to inform budget creation and identify areas for spending improvement."
    )
    if not success:
        return False, lookup_result

    # Step 2: Create the explicit budget cap requested by the user.
    success, creation_result = create_budget_or_goal(
        creation_request="Set a budget cap of $800 specifically for the final week of this month.",
        input_info=lookup_result
    )
    if not success:
        # If creation fails, we still attempt strategy based on the lookup data, but report the creation failure.
        creation_status = f"Budget Creation Failed: {creation_result}"
    else:
        creation_status = f"Budget Created: {creation_result}"

    # Step 3: Provide strategies for improvement by comparing the current spending patterns 
    # (derived from the lookup) against the previous month's spending.
    success, strategy_result = research_and_strategize_financial_outcomes(
        strategize_request="Based on the comparison between this week's spending and last week's spending from the previous month, provide actionable steps and strategies on how the user can improve their spending habits.",
        input_info=lookup_result
    )
    if not success:
        strategy_status = f"Strategy Generation Failed: {strategy_result}"
    else:
        strategy_status = f"Improvement Strategy: {strategy_result}"
    
    # Combine results
    if creation_result and strategy_result:
        return True, f"{creation_status}. {strategy_status}"
    elif creation_result:
        return True, f"{creation_status}. {strategy_status}"
    else:
        # If creation failed, we still return success if strategy was successful, or failure if both failed.
        return False, f"{creation_status}. {strategy_status}"
"""

  execution_result_1 = """lookup_user_accounts_transactions_income_and_spending_patterns:
  lookup_request: Analyze user spending data, comparing the last seven days of the current month against the last seven days of the previous month, to inform budget creation and identify areas for spending improvement.
  input_info: None

create_budget_or_goal:
  creation_request: Set a budget cap of $800 specifically for the final week of this month.
  input_info: Spending Comparison: Last 7 Days (Current Month) vs. Previous 7 Days
Current Period: 2025-11-29 to 2025-12-05
Previous Period: 2025-11-24 to 2025-11-30

Current Period Total: $4339
Current Period Breakdown:
  - shelter_home: $2850
  - education_tuition: $500
  - bills_service_fees: $276
  - meals_groceries: $196
  - leisure_entertainment: $159
  - meals_dining_out: $137
  - transportation_car: $101
  - donations_gifts: $83
  - education_kids_activities: $36
  - transfers: $0

Previous Period Total: $788
Previous Period Breakdown:
  - meals_dining_out: $302
  - leisure_entertainment: $286
  - meals_groceries: $183
  - education_kids_activities: $17
  - transfers: $0

Comparison Summary:
Total Change: $3551
Spending increased compared to the previous period. Review categories that grew the most for potential budget adjustments.

Top 3 Categories with Increased Spending:
  - education_kids_activities: Increased by $19
  - meals_groceries: Increased by $14

research_and_strategize_financial_outcomes:
  strategize_request: Based on the comparison between this week's spending and last week's spending from the previous month, provide actionable steps and strategies on how the user can improve their spending habits.
  input_info: Spending Comparison: Last 7 Days (Current Month) vs. Previous 7 Days
Current Period: 2025-11-29 to 2025-12-05
Previous Period: 2025-11-24 to 2025-11-30

Current Period Total: $4339
Current Period Breakdown:
  - shelter_home: $2850
  - education_tuition: $500
  - bills_service_fees: $276
  - meals_groceries: $196
  - leisure_entertainment: $159
  - meals_dining_out: $137
  - transportation_car: $101
  - donations_gifts: $83
  - education_kids_activities: $36
  - transfers: $0

Previous Period Total: $788
Previous Period Breakdown:
  - meals_dining_out: $302
  - leisure_entertainment: $286
  - meals_groceries: $183
  - education_kids_activities: $17
  - transfers: $0

Comparison Summary:
Total Change: $3551
Spending increased compared to the previous period. Review categories that grew the most for potential budget adjustments.

Top 3 Categories with Increased Spending:
  - education_kids_activities: Increased by $19
  - meals_groceries: Increased by $14
"""

  past_review_outcomes = [
    {
      "generated_code": generated_code_1,
      "execution_result": execution_result_1,
      "output": {
        "good_copy": True,
        "info_correct": False,
        "eval_text": "Date calculation in the code was incorrect. lookup_request misinterepreted \"final week of this month\" to the most recent week that passed."
      }
    }
  ]

  return _run_test_with_logging(last_user_request, previous_conversation, generated_code, execution_result, past_review_outcomes, checker)


def main(batch: int = 1):
  """
  Main function to test the checker optimizer
  
  Args:
    batch: Batch number (1, 2, 3, or 4) to determine which tests to run
  """
  print("Testing CheckGoalAgentOptimizer\n")
  
  if batch == 1:
    # Basic correct cases
    print("Test 1: Correct simple lookup")
    print("-" * 80)
    test_long_conversation_with_previous_conversation()
    print("\n")
    print("Test 2: Correct goal creation with lookup")
    print("-" * 80)
    # test_correct_goal_creation_with_lookup()
    # print("\n")
    # # Correct complex cases
    # print("Test 1: Correct goal setting with strategize")
    # print("-" * 80)
    # test_correct_goal_setting_with_strategize()
    # print("\n")
  # elif batch == 2:
  #   # Incorrect efficiency cases
  #   print("Test 1: Incorrect unnecessary chaining")
  #   print("-" * 80)
  #   test_incorrect_unnecessary_chaining()
  #   print("\n")
    
  #   print("Test 2: Incorrect missing lookup for data request")
  #   print("-" * 80)
  #   test_incorrect_missing_lookup_for_data_request()
  #   print("\n")
  #   # Incorrect code structure cases
  #   print("Test 1: Incorrect missing error handling")
  #   print("-" * 80)
  #   test_incorrect_missing_error_handling()
  #   print("\n")
  # elif batch == 3:
  #   print("Test 2: Past review outcomes issue persists")
  #   print("-" * 80)
  #   test_past_review_outcomes_issue_persists()
  #   print("\n")
  else:
    raise ValueError("batch must be 1, 2, 3, or 4")
  
  print("All tests completed!")


if __name__ == "__main__":
  import argparse
  parser = argparse.ArgumentParser(description='Run tests in batches')
  parser.add_argument('--batch', type=int, default=1, choices=[1, 2, 3, 4],
                      help='Batch number to run (1, 2, 3, or 4)')
  args = parser.parse_args()
  main(batch=args.batch)

