from google import genai
from google.genai import types
import os
import json
from typing import Optional
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

SYSTEM_PROMPT = """You are a checker verifying goal agent optimizer outputs against rules.

## Input:
- **EVAL_INPUT**: Last User Request (user's last message), Previous Conversation (exchanges to contextualize Last User Request)
- **GENERATED_CODE**: Python code generated by the goal agent optimizer (string)
- **EXECUTION_RESULT**: Full execution log from running the generated code (string). Contains function calls, their parameters, return values, and final result.
- **PAST_REVIEW_OUTCOMES**: Array of past reviews, each with `generated_code`, `execution_result`, `good_copy`, `info_correct`, `eval_text`

## Output:
Only review the generated code and execution results. The inputs of each tool are out of scope.

JSON: `{"good_copy": boolean, "info_correct": boolean, "eval_text": string}`
- `good_copy`: **(CODE QUALITY & PLAN LOGIC)** True if `GENERATED_CODE` perfectly follows all rules in the "Rules" section. This includes:
    - Correct code structure and function definition.
    - **Skill Accuracy**: Proper skills are called to accurately and effectively respond to the user request.
    - High-quality, natural language request parameters that incorporate context.
    - Proper error handling logic (return False, error_msg on failure, unless failure is from a non-critical lookup that is intended to be used as optional context).
- `info_correct`: **(EXECUTION ACCURACY & DATA TRUTH)** True if `EXECUTION_RESULT` shows that the plan was executed accurately against the `EVAL_INPUT`. This includes:
    - The execution log shows the correct skills were actually called with appropriate parameters.
    - The final string result (second element of the return tuple) from `execute_plan()` correctly addresses the `Last User Request` based on the data provided in the execution.
    - **Feasibility Alignment**: 
        a) Evaluate if the `Last User Request` is feasible based on available skills and data in `EXECUTION_RESULT`.
        b) Check if your evaluation of feasibility aligns with the actual `True/False` status returned by `execute_plan()`. 
        c) If misaligned (e.g., request is feasible but code returned `False`, or request is unsupported but code returned `True`), `info_correct` MUST be `False`.
- `eval_text`: Required ONLY if either boolean is False. Must be an empty string if both `good_copy` and `info_correct` are True. Explains why without referring to the guidelines as "Rule 1", "Rule 2", etc. Be specific and concise (less than 25 words).

## Critical Priority: Learn from PAST_REVIEW_OUTCOMES
**MANDATORY**: If PAST_REVIEW_OUTCOMES flags issues that still exist in GENERATED_CODE or EXECUTION_RESULT, mark as incorrect.
- Extract all issues from past `eval_text` fields.
- Check if the current GENERATED_CODE or EXECUTION_RESULT repeats the same mistakes.
- If past reviews flagged a missing step or improper skill use, and it's still present → mark `good_copy: False`.
- If past reviews flagged an execution error, and it's still present → mark `info_correct: False`.
- Do not repeat previously identified errors in `eval_text` if they have been fixed, but ALWAYS flag them if they persist.

## Rules

### Code Structure (`good_copy` ONLY)
1. **Function Definition**: Must define `execute_plan()` function that takes no arguments and returns `tuple[bool, str]`.
2. **Only Skill Functions**: Code should only use the available skill functions:
   - `lookup_user_accounts_transactions_income_and_spending_patterns(lookup_request: str, input_info: str = None) -> tuple[bool, str]`
   - `create_budget_or_goal(creation_request: str, input_info: str = None) -> tuple[bool, str]`
   - `research_and_strategize_financial_outcomes(strategize_request: str, input_info: str = None) -> tuple[bool, str]`
   - `update_transaction_category_or_create_category_rules(categorize_request: str, input_info: str = None) -> tuple[bool, str]`
3. **No Other Python Functions**: Should not use other Python functions beyond skill functions, conditional operations, and string concatenations. No imports, no datetime operations, no other libraries.
4. **Error Handling**: Critical skills must check `success` and return early if `success` is False. However, non-critical lookup skills (Step 1) do not have to return early on failure and can proceed to the next step if the next step can handle missing or error-based context. Passing a lookup's failure result as `input_info` to a subsequent skill is acceptable and should not be penalized as "inappropriate parameters" if the intention is to provide whatever context is available.

### Task Prioritization (`good_copy` ONLY)
1. **Always Assume Financial Goal Context**: Interpret Last User Request and Previous Conversation as exchanges that followed the prompt "What are your financial goals?".
2. **Prioritize Last User Request**: The code must directly address the Last User Request. Steps should only be for achieving the Last User Request. Avoid adding steps related to past topics unless absolutely necessary.
3. **Use Previous Conversation Appropriately**:
   - For all skill requests, must thoroughly analyze Previous Conversation to gain accurate understanding of user's intent and ensure request parameters are comprehensive and contextually relevant.
   - If Previous Conversation contains the EXACT, COMPLETE information needed (e.g., current spending amount), it can be incorporated directly without a lookup step.
4. **Extract Key Information**: Vigilantly identify and extract critical details from the user's request, such as amounts and timelines.
5. **Handle Multiple Goals Sequentially**: Address multiple goals one by one in the plan.

### Goal-Oriented Flow (`good_copy` ONLY)
1. **Step 1: Gather Data (If Necessary)**: For goal-oriented requests, gather data if needed:
   - Data on user's finances: use `lookup_user_accounts_transactions_income_and_spending_patterns`
   - Data outside user's finances (requiring research): use `research_and_strategize_financial_outcomes`
   - If Previous Conversation contains the EXACT, COMPLETE information needed, this step can be skipped
2. **Step 2: Strategize (If Complex)**: If the goal is complex (e.g., retirement planning, college savings, debt paydown strategy), use `research_and_strategize_financial_outcomes` to create a clear strategy. Simple savings goals for a specific item do not usually require this step.
3. **Step 3: Create Goal (Default Final Step)**: This is the default final step for goal-oriented requests. Use all gathered information and strategy to make a precise `creation_request` with `create_budget_or_goal`.

### Information-Seeking Flow (`good_copy` ONLY)
1. **Question-Based Requests**: If the user asks a question, the plan should consist of the necessary `lookup` or `research` skills to acquire the information.
2. **Return Information Directly**: The plan's final output should be the information itself. Do NOT use `create_budget_or_goal` for information-seeking requests.
3. **Use Appropriate Skill**: 
   - Use `lookup_user_accounts_transactions_income_and_spending_patterns` for questions about user's own financial data
   - Use `research_and_strategize_financial_outcomes` for questions requiring external research or general financial advice

### Categorization Flow (`good_copy` ONLY)
1. **Must Use Categorization Skill**: If the user wants to categorize transactions or create categorization rules, the plan MUST use the `update_transaction_category_or_create_category_rules` skill.
2. **Category Rules**: If user hints at doing this in the future as well, specify that a category rule needs to be created on top of updating transaction categories.

### Skill Selection Guidelines (`good_copy` ONLY)
1. **Effective Skill Choice**: Must select the most direct and effective skills for the task. 
   - Do not use `create_budget_or_goal` for questions.
   - Use `lookup_user_accounts_transactions_income_and_spending_patterns` for any personal financial data needs.
   - Use `research_and_strategize_financial_outcomes` only for external data or complex planning.
   - Using an incorrect skill for the request type (e.g., using `create_budget_or_goal` to answer "how much did I spend") must result in `good_copy: False`.
2. **create_budget_or_goal Usage**: 
   - This is the default final step for goal-oriented requests
   - Should NOT be used for categorization tasks
   - Should NOT be used for information-seeking questions
   - Should be used when user states a financial goal (explicit or implicit)
2. **research_and_strategize_financial_outcomes Usage**:
   - Use for research (e.g., "average dining out for a couple in Chicago", "estimated cost of a flight from Manila to Greece")
   - Use for creating complex financial plans requiring simulation or forecasting beyond simple data lookups
   - Do NOT use to analyze the user's own data; use `lookup_user_accounts_transactions_income_and_spending_patterns` for that
3. **lookup_user_accounts_transactions_income_and_spending_patterns Usage**:
   - Use for all questions about user's accounts, transactions, income, spending, subscriptions
   - Use for comparisons, summaries, calculations, and assessments on user data
   - Use for forecasted income and spending
   - Can be skipped if Previous Conversation contains the EXACT, COMPLETE information needed

### Request Parameter Quality (`good_copy` ONLY)
1. **Comprehensive Request Parameters**: Request parameters must effectively incorporate relevant information from Previous Conversation and, when available, the `input_info`. If `input_info` contains a failure message from a previous non-critical lookup, it is acceptable to pass it along as context; the subsequent skill is responsible for handling it.
2. **Natural Language**: Request parameters must be written in natural language and be descriptive enough to capture the user's intent comprehensively.
3. **Context Incorporation**: When `input_info` is available, must incorporate it concisely into subsequent skill function calls. The `input_info` should refine and enhance the request parameter.
4. **Multiple Requests Support**: All skill functions can accept multiple requests written as multiple sentences in their request parameters. Use this capability when appropriate.

### Execution Result (`info_correct` ONLY)
1. **Execution Logic and Outcome**: EXECUTION_RESULT should show that the plan was executed as intended and reached a logically correct outcome.
    - **Feasibility Check**: Determine if the request is supported by the skills. If it is supported, `execute_plan()` should return `True` on successful execution. If it is unsupported, it should return `False`.
    - **Alignment**: If the code returns `True` for an unsupported request, or `False` for a supported and successfully executed request, mark `info_correct: False`.
    - **Expected Handled State**: If a critical skill call fails (e.g., database error), `execute_plan()` should return `False` with a clear explanation. This is a correctly handled failure.
2. **Final Output Relevance**: The final string result from `execute_plan()` must directly and fully answer the Last User Request. All of the user's requests must be answered by the output of `execute_plan()`.
3. **Function Call Appropriateness**: All function calls in EXECUTION_RESULT should match what the GENERATED_CODE intended. Check that function names match, request parameters are appropriate and contextually relevant, and `input_info` is properly passed between functions when chaining.
4. **Error Handling in Execution**: If execution failed (e.g., a skill returned `False`), the output should contain meaningful error information or indicate what additional information is needed. The code should have handled errors gracefully. info_correct is True only if the `True/False` status of the final result matches the logical reality of the execution.

### Unsupported Requests Policy
1. **Identify Unsupported Requests**: If the Last User Request is something that cannot be fulfilled by the provided skills, the `GENERATED_CODE` should return `False` and a message explaining it's unsupported.
2. **Correctness of Unsupported Response**: 
    - If the code correctly identifies a request as unsupported and returns an appropriate explanation, mark `good_copy: True` and `info_correct: True`.
    - It is INCORRECT for the code to attempt to use a skill for a purpose it's not intended for.
    - It is INCORRECT for the code to imply it can do something it cannot.
3. **Smooth Execution**: If the code returns a clear "unsupported" message with `False` status, this is considered a successful addressal of the request. The `eval_text` MUST be an empty string if an unsupported request is handled correctly with a `False` status and clear explanation.

## Verification Logic

**Step 1: Skill Suitability Check**
- Identify the nature of the `Last User Request` (Information seeking? Goal setting? Categorization?).
- Verify if the skills used in `GENERATED_CODE` are the most direct and effective for this nature. If not, `good_copy` is False.

**Step 2: Feasibility & Alignment Check**
1. **Determine Feasibility**: Based on the `EXECUTION_RESULT` and available skills, is the user's request something that *can* be fulfilled?
2. **Check execute_plan() Status**:
   - If the request is feasible and executed successfully, `execute_plan()` MUST return `True`.
   - If the request is unsupported OR if a critical skill failed, `execute_plan()` MUST return `False`.
3. **Compare**: If the code's `True/False` status does not align with the feasibility/outcome (e.g., returned `True` but failed/unsupported), `info_correct` is False.

**Step 3: Response Completeness**
- Ensure the output string from `execute_plan()` answers ALL parts of the user request.

## Verification Steps

**CRITICAL PRIORITY: FEASIBILITY ALIGNMENT**
1. Analyze the request's feasibility against skills.
2. Check if `execute_plan()`'s True/False status reflects this feasibility.
3. If misaligned, mark `info_correct: False` and explain.

1. **Check PAST_REVIEW_OUTCOMES first**: Extract all flagged issues. If GENERATED_CODE or EXECUTION_RESULT repeats them → mark False
2. **Verify good_copy**: Follow Step 1 of Verification Logic.
3. **Verify info_correct**: Follow Step 2 & 3 of Verification Logic.
4. **Write eval_text**: If good_copy and/or info_correct is False, explain the specific issues. If BOTH are True, eval_text MUST be an empty string "".
--
"""

class CheckGoalAgentOptimizer:
  """Handles all Gemini API interactions for checking goal agent optimizer outputs against rules"""
  
  def __init__(self, model_name="gemini-3-flash-preview"):
    """Initialize the Gemini agent with API configuration for checking goal agent optimizer evaluations"""
    # API Configuration
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
      raise ValueError("GEMINI_API_KEY environment variable is not set. Please set it in your .env file or environment.")
    self.client = genai.Client(api_key=api_key)
    
    # Model Configuration
    self.thinking_budget = 8196
    self.model_name = model_name
    
    # Generation Configuration Constants
    self.temperature = 0.6
    self.top_p = 0.95
    self.max_output_tokens = 8192
    
    # Safety Settings
    self.safety_settings = [
      types.SafetySetting(category="HARM_CATEGORY_HATE_SPEECH", threshold="OFF"),
      types.SafetySetting(category="HARM_CATEGORY_DANGEROUS_CONTENT", threshold="OFF"),
      types.SafetySetting(category="HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold="OFF"),
      types.SafetySetting(category="HARM_CATEGORY_HARASSMENT", threshold="OFF")
    ]
    
    # System Prompt
    self.system_prompt = SYSTEM_PROMPT

  
  def generate_response(self, request_text) -> dict:
    """
    Generate a response using Gemini API for checking goal agent optimizer evaluations.
    
    Args:
      request_text: Formatted request text containing EVAL_INPUT, GENERATED_CODE, EXECUTION_RESULT, and optional PAST_REVIEW_OUTCOMES
      
    Returns:
      Dictionary with good_copy, info_correct, and eval_text keys
    """
    # Create content and configuration
    contents = [types.Content(role="user", parts=[request_text])]
    
    generate_content_config = types.GenerateContentConfig(
      temperature=self.temperature,
      top_p=self.top_p,
      max_output_tokens=self.max_output_tokens,
      safety_settings=self.safety_settings,
      system_instruction=[types.Part.from_text(text=self.system_prompt)],
      thinking_config=types.ThinkingConfig(thinking_budget=self.thinking_budget),
    )

    # Generate response
    output_text = ""
    for chunk in self.client.models.generate_content_stream(
      model=self.model_name,
      contents=contents,
      config=generate_content_config,
    ):
      if chunk.text is not None:
        output_text += chunk.text
    
    # Check if response is empty
    if not output_text or not output_text.strip():
      raise ValueError(f"Empty response from model. Check API key and model availability.")
    
    # Parse JSON response
    try:
      # Remove markdown code blocks if present
      if "```json" in output_text:
        json_start = output_text.find("```json") + 7
        json_end = output_text.find("```", json_start)
        if json_end != -1:
          output_text = output_text[json_start:json_end].strip()
      elif "```" in output_text:
        # Try to find JSON in code blocks
        json_start = output_text.find("```") + 3
        json_end = output_text.find("```", json_start)
        if json_end != -1:
          output_text = output_text[json_start:json_end].strip()
      
      # Try parsing the whole response first
      parsed = json.loads(output_text.strip())
      
      # Ensure it has the required keys
      if not isinstance(parsed, dict):
        raise ValueError(f"Expected dict, got {type(parsed)}")
      
      if "good_copy" not in parsed or "info_correct" not in parsed:
        raise ValueError(f"Missing required keys: good_copy, info_correct")
      
      return parsed
    except json.JSONDecodeError as e:
      raise ValueError(f"Failed to parse JSON response: {e}\nResponse length: {len(output_text)}\nResponse preview: {output_text[:500]}")


def _run_test_with_logging(last_user_request: str, previous_conversation: Optional[str] = None, generated_code: str = "", execution_result: str = "", past_review_outcomes: Optional[list] = None, checker: Optional[CheckGoalAgentOptimizer] = None):
  """
  Internal helper function that runs a test with consistent logging.
  
  Args:
    last_user_request: The user's most recent request (string)
    previous_conversation: The conversation history before the last user request (string)
    generated_code: The Python code generated by the goal agent optimizer (string)
    execution_result: Full execution log from running the generated code (string)
    past_review_outcomes: Optional array of past review outcomes, each containing `generated_code`, `execution_result`, `good_copy`, `info_correct`, and `eval_text`
    checker: Optional CheckGoalAgentOptimizer instance. If None, creates a new one.
    
  Returns:
    Dictionary with good_copy, info_correct, and eval_text keys, or None if error occurred
  """
  if checker is None:
    checker = CheckGoalAgentOptimizer()
  
  # Print the exact input that will be passed to the LLM
  past_review_section = ""
  if past_review_outcomes:
    # Loop through past_review_outcomes and add each to the past_review_section
    for index, past_review_outcome in enumerate(past_review_outcomes):
      past_review_section += f"""<PAST_REVIEW_OUTCOME_{index + 1}>

## Generated Code for #{index + 1}

```python
{past_review_outcome['generated_code']}
```

## Execution Result for #{index + 1}

{past_review_outcome['execution_result']}

## Evaluation Output for #{index + 1}

```json
{json.dumps(past_review_outcome['output'], indent=2)}
```

</PAST_REVIEW_OUTCOME_{index + 1}>

"""
  
  if previous_conversation:
    previous_conversation_section = f"""**Previous Conversation**:
{previous_conversation}"""
  else:
    previous_conversation_section = """**Previous Conversation**:
None"""

  request_str = f"""<EVAL_INPUT>
**Last User Request**: {last_user_request}
{previous_conversation_section}
</EVAL_INPUT>

<GENERATED_CODE>

```python
{generated_code}
```

</GENERATED_CODE>

<EXECUTION_RESULT>

{execution_result}

</EXECUTION_RESULT>

{past_review_section}

Output:"""
  
  print("=" * 80)
  print("LLM INPUT:")
  print("=" * 80)
  print(request_str)
  print("=" * 80)
  print()
  
  try:
    result = checker.generate_response(types.Part.from_text(text=request_str))
    
    print("=" * 80)
    print("LLM OUTPUT:")
    print("=" * 80)
    print(json.dumps(result, indent=2))
    print("=" * 80)
    print()
    
    return result
  except Exception as e:
    print(f"ERROR: {type(e).__name__}: {str(e)}")
    import traceback
    print(traceback.format_exc())
    print("=" * 80)
    print()
    return None


def test_vacation_fund_goal_with_error_handling(checker: CheckGoalAgentOptimizer = None):
  """
  Test method for vacation fund goal creation with error handling issues.
  
  Args:
    checker: Optional CheckGoalAgentOptimizer instance. If None, creates a new one.
    
  Returns:
    Dictionary with good_copy, info_correct, and eval_text keys
  """
  last_user_request = "Create a vacation fund goal of $3,000 for a trip to Japan next October."
  previous_conversation = None

  generated_code = """def execute_plan() -> tuple[bool, str]:
    # Step 1: Gather Data (Lookup current finances to assess feasibility for saving $3,000 by next October)
    success, lookup_result = lookup_user_accounts_transactions_income_and_spending_patterns(
        lookup_request="Analyze current savings capacity and recurring expenses to determine the required monthly contribution needed to save $3,000 for a vacation trip to Japan by next October."
    )
    if not success:
        # If lookup fails or needs more context, we pass the result to the next step, 
        # which might be creation or strategy, or it might prompt the user for more info if creation is called next.
        pass
    # Step 2 & 3: Strategize (if needed) and Create Goal
    # For a specific savings target, we often go straight to creation, letting the creation skill prompt for missing details 
    # (like current savings rate or exact current date if needed for calculation) if the lookup wasn't enough.
    
    success, creation_result = create_budget_or_goal(
        creation_request="Create a dedicated vacation fund goal of $3,000 for a trip to Japan scheduled for next October.",
        input_info=lookup_result
    )
    if not success:
        return False, creation_result
    
    return True, creation_result
"""

  execution_result = """lookup_user_accounts_transactions_income_and_spending_patterns:
  lookup_request: Analyze current savings capacity and recurring expenses to determine the required monthly contribution needed to save $3,000 for a vacation trip to Japan by next October.
  input_info: None
  return: (False, "Error calling P:Func:LookupUserData template: 'NoneType' object has no attribute 'cursor'")
create_budget_or_goal:
  creation_request: Create a dedicated vacation fund goal of $3,000 for a trip to Japan scheduled for next October.
  input_info: Error calling P:Func:LookupUserData template: 'NoneType' object has no attribute 'cursor'
  return: (False, "Error calling P:Func:CreateBudgetOrGoalOrReminder template: 'NoneType' object has no attribute 'cursor'")
execute_plan:
False
Error calling P:Func:CreateBudgetOrGoalOrReminder template: 'NoneType' object has no attribute 'cursor'
"""

  return _run_test_with_logging(last_user_request, previous_conversation, generated_code, execution_result, None, checker)


def test_incorrect_unnecessary_chaining(checker: CheckGoalAgentOptimizer = None):
  last_user_request = "What was my total spending on groceries last month?"
  previous_conversation = "User: How much did I spend on dining out last month?\nAssistant: You spent $450 on dining out."
  
  generated_code = """def execute_plan() -> tuple[bool, str]:
    success, lookup_result = lookup_user_accounts_transactions_income_and_spending_patterns(
        lookup_request="Calculate total spending on groceries last month."
    )
    if not success:
        return False, lookup_result
    
    # Unnecessary chaining: research is not needed for a simple grocery lookup
    success, research_result = research_and_strategize_financial_outcomes(
        strategize_request="Provide general tips on how to save on groceries based on this spending: " + lookup_result
    )
    if not success:
        return False, research_result
        
    return True, lookup_result + "\\n\\nTips: " + research_result
"""
  execution_result = """lookup_user_accounts_transactions_income_and_spending_patterns:
  lookup_request: Calculate total spending on groceries last month.
  return: (True, "Your total spending on groceries last month was $350.")
research_and_strategize_financial_outcomes:
  strategize_request: Provide general tips on how to save on groceries based on this spending: Your total spending on groceries last month was $350.
  return: (True, "1. Use coupons. 2. Buy in bulk.")
execute_plan:
True
Your total spending on groceries last month was $350.

Tips: 1. Use coupons. 2. Buy in bulk."""

  return _run_test_with_logging(last_user_request, previous_conversation, generated_code, execution_result, None, checker)

def test_incorrect_missing_lookup_for_data_request(checker: CheckGoalAgentOptimizer = None):
  last_user_request = "Can I afford a $500 bike this month?"
  previous_conversation = None
  
  generated_code = """def execute_plan() -> tuple[bool, str]:
    # Missing lookup for current month's remaining budget/spending
    success, creation_result = create_budget_or_goal(
        creation_request="Create a goal for a $500 bike."
    )
    if not success:
        return False, creation_result
    return True, creation_result
"""
  execution_result = """create_budget_or_goal:
  creation_request: Create a goal for a $500 bike.
  return: (True, "Goal for $500 bike created.")
execute_plan:
True
Goal for $500 bike created."""

  return _run_test_with_logging(last_user_request, previous_conversation, generated_code, execution_result, None, checker)

def test_incorrect_missing_error_handling(checker: CheckGoalAgentOptimizer = None):
  last_user_request = "Move my grocery transactions to the 'Food' category."
  previous_conversation = None
  
  generated_code = """def execute_plan() -> tuple[bool, str]:
    success, result = update_transaction_category_or_create_category_rules(
        categorize_request="Move all grocery transactions to 'Food' category."
    )
    # Missing if not success check
    return True, result
"""
  execution_result = """update_transaction_category_or_create_category_rules:
  categorize_request: Move all grocery transactions to 'Food' category.
  return: (False, "Database connection error.")
execute_plan:
True
Database connection error."""

  return _run_test_with_logging(last_user_request, previous_conversation, generated_code, execution_result, None, checker)

def test_past_review_outcomes_issue_persists(checker: CheckGoalAgentOptimizer = None):
  last_user_request = "I want to save $1000 for a new laptop."
  previous_conversation = None
  
  generated_code = """def execute_plan() -> tuple[bool, str]:
    success, result = create_budget_or_goal(
        creation_request="Save $1000 for a laptop."
    )
    if not success:
        return False, result
    return True, result
"""
  execution_result = """create_budget_or_goal:
  creation_request: Save $1000 for a laptop.
  return: (True, "Goal created.")
execute_plan:
True
Goal created."""

  past_review_outcomes = [
    {
      "generated_code": generated_code,
      "execution_result": execution_result,
      "output": {
        "good_copy": False,
        "info_correct": True,
        "eval_text": "The plan should first lookup current finances to see if $1000 is feasible."
      }
    }
  ]

  return _run_test_with_logging(last_user_request, previous_conversation, generated_code, execution_result, past_review_outcomes, checker)

def test_unsupported_request_handling(checker: CheckGoalAgentOptimizer = None):
  last_user_request = "Book a flight to Paris for me."
  previous_conversation = None
  
  generated_code = """def execute_plan() -> tuple[bool, str]:
    # This is unsupported by the current skills
    return False, "I'm sorry, I cannot book flights directly. I can help you research the cost or set a savings goal for it."
"""
  execution_result = """execute_plan:
False
I'm sorry, I cannot book flights directly. I can help you research the cost or set a savings goal for it."""

  return _run_test_with_logging(last_user_request, previous_conversation, generated_code, execution_result, None, checker)

def test_handled_error_execution(checker: CheckGoalAgentOptimizer = None):
  last_user_request = "What is my current balance?"
  previous_conversation = None
  
  generated_code = """def execute_plan() -> tuple[bool, str]:
    success, result = lookup_user_accounts_transactions_income_and_spending_patterns(
        lookup_request="Get current balance for all accounts."
    )
    if not success:
        return False, "I encountered an error while fetching your balances: " + result
    return True, result
"""
  execution_result = """lookup_user_accounts_transactions_income_and_spending_patterns:
  lookup_request: Get current balance for all accounts.
  return: (False, "Service temporarily unavailable.")
execute_plan:
False
I encountered an error while fetching your balances: Service temporarily unavailable."""

  return _run_test_with_logging(last_user_request, previous_conversation, generated_code, execution_result, None, checker)

def test_incorrect_success_on_failure(checker: CheckGoalAgentOptimizer = None):
  last_user_request = "Move my grocery transactions to the 'Food' category."
  previous_conversation = None
  
  generated_code = """def execute_plan() -> tuple[bool, str]:
    success, result = update_transaction_category_or_create_category_rules(
        categorize_request="Move all grocery transactions to 'Food' category."
    )
    # Incorrectly returns True even if success is False
    return True, result
"""
  execution_result = """update_transaction_category_or_create_category_rules:
  categorize_request: Move all grocery transactions to 'Food' category.
  return: (False, "Database connection error.")
execute_plan:
True
Database connection error."""

  return _run_test_with_logging(last_user_request, previous_conversation, generated_code, execution_result, None, checker)

def test_incorrect_failure_on_success(checker: CheckGoalAgentOptimizer = None):
  last_user_request = "What is my total spending on groceries?"
  previous_conversation = None
  
  generated_code = """def execute_plan() -> tuple[bool, str]:
    success, result = lookup_user_accounts_transactions_income_and_spending_patterns(
        lookup_request="Total grocery spending."
    )
    # Incorrectly returns False even if success is True
    return False, result
"""
  execution_result = """lookup_user_accounts_transactions_income_and_spending_patterns:
  lookup_request: Total grocery spending.
  return: (True, "Your total grocery spending is $150.")
execute_plan:
False
Your total grocery spending is $150."""

  return _run_test_with_logging(last_user_request, previous_conversation, generated_code, execution_result, None, checker)

def main(batch: int = 1):
  """
  Main function to test the checker optimizer
  
  Args:
    batch: Batch number (1, 2, 3, 4, 5, or 6) to determine which tests to run
  """
  print("Testing CheckGoalAgentOptimizer\n")
  
  if batch == 1:
    # Primary test case: Vacation fund goal with error handling issues
    print("Test 1: Vacation fund goal with error handling issues")
    print("-" * 80)
    test_vacation_fund_goal_with_error_handling()
    print("\n")
  elif batch == 2:
    # Incorrect efficiency cases
    print("Test 1: Incorrect unnecessary chaining")
    print("-" * 80)
    test_incorrect_unnecessary_chaining()
    print("\n")
    
    print("Test 2: Incorrect missing lookup for data request")
    print("-" * 80)
    test_incorrect_missing_lookup_for_data_request()
    print("\n")
    # Incorrect code structure cases
    print("Test 3: Incorrect missing error handling")
    print("-" * 80)
    test_incorrect_missing_error_handling()
    print("\n")
  elif batch == 3:
    print("Test 1: Past review outcomes issue persists")
    print("-" * 80)
    test_past_review_outcomes_issue_persists()
    print("\n")
  elif batch == 4:
    print("Test 1: Unsupported request handling")
    print("-" * 80)
    test_unsupported_request_handling()
    print("\n")
  elif batch == 5:
    print("Test 1: Handled error execution (should be info_correct: True)")
    print("-" * 80)
    test_handled_error_execution()
    print("\n")
  elif batch == 6:
    print("Test 1: Incorrect Success on Failure (should be info_correct: False)")
    print("-" * 80)
    test_incorrect_success_on_failure()
    print("\n")
    
    print("Test 2: Incorrect Failure on Success (should be info_correct: False)")
    print("-" * 80)
    test_incorrect_failure_on_success()
    print("\n")
  else:
    raise ValueError("batch must be 1, 2, 3, 4, 5, or 6")
  
  print("All tests completed!")


if __name__ == "__main__":
  import argparse
  parser = argparse.ArgumentParser(description='Run tests in batches')
  parser.add_argument('--batch', type=int, default=1, choices=[1, 2, 3, 4, 5, 6],
                      help='Batch number to run (1, 2, 3, 4, 5, or 6)')
  args = parser.parse_args()
  main(batch=args.batch)

