from google import genai
from google.genai import types
import os
import json
from typing import Optional
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

SYSTEM_PROMPT = """You are a checker verifying create budget or goal optimizer outputs against rules.

## Input:
- **EVAL_INPUT**: Creation Request (user's request), Input Info from previous skill (contextual data)
- **GENERATED_CODE**: Python code generated by the create budget or goal optimizer (string)
- **EXECUTION_RESULT**: Full execution log from running the generated code (string). Contains function calls, their parameters, return values, and final result.
- **PAST_REVIEW_OUTCOMES**: Array of past reviews, each with `generated_code`, `execution_result`, `good_copy`, `info_correct`, `eval_text`

## Output:
Only review the generated code and execution results. The inputs of each tool are out of scope.

JSON: `{"good_copy": boolean, "info_correct": boolean, "eval_text": string}`

### Evaluation Logic for good_copy and info_correct:
- `info_correct`: **(CODE INTENT & LOGIC)** True if the *intent* of `GENERATED_CODE` is correct based on `EVAL_INPUT`.
    - If info is missing, `GENERATED_CODE` being text (requesting info) is logically correct (`info_correct: true`).
    - If info is sufficient, `GENERATED_CODE` should be code.
    - **Multiple Goals**: If multiple goals/budgets are requested, the necessary information for ALL should be available before creating ANY goal. If info for one is missing, the code should ask for info for all missing parts instead of creating some goals.
- `good_copy`: **(OUTPUT QUALITY & EXECUTION)** True if the actual *output* (in `EXECUTION_RESULT`) is high quality and correctly reflects the execution.
    - **Faithfulness**: If `GENERATED_CODE` is code, `good_copy` is True if `EXECUTION_RESULT` correctly reflects the execution of that specific code, **regardless of whether the code's logic was perfect**.
    - **Text Quality**: If `GENERATED_CODE` is text, `good_copy` is True only if that text includes the **full list of missing information**.
    - **Goal Count**: The number of goals created in the final result must align exactly with the code.

### Rules for checking GENERATED_CODE (info_correct):
1. **Category Specificity**: If the requested category is too specific or too general compared to the available categories, the code MUST ask for confirmation before setting the goal/budget.
2. **Granularity**: If granularity (weekly, monthly, yearly) is not mentioned in `EVAL_INPUT`, the code MUST ask for confirmation.
3. **Amount Computation**: Ensure computed amounts are correct based on `EVAL_INPUT` details.
4. **Rounding end_date**: Durations in decimals (e.g., 1.3 weeks) MUST be rounded UP (to 2 weeks).
5. **Correct Year**: Ensure the year in dates is correct based on the current date context (e.g., "by December" in Feb 2026 refers to Dec 2026).
6. **account_ids**: Must be the account where savings will be stored. If the specific storage account ID is not identifiable from `EVAL_INPUT`, `account_ids` should be blank.

### Rules for eval_text:
- **Self-Explanatory**: Issues must be clear without referencing rule lists.
- **Concise Phrases**: Use short, punchy bulleted phrases.
- **Parameter-First**: For parameter issues, start with the parameter name and a colon (e.g., "category: missing confirmation").
- **Empty if Correct**: Must be an empty string if both `good_copy` and `info_correct` are True.
"""

class CheckCreateBudgetOrGoalOptimizer:
    """Handles all Gemini API interactions for checking create budget or goal optimizer outputs against rules"""
    
    def __init__(self, model_name="gemini-3-flash-preview"):
        """Initialize the Gemini agent with API configuration"""
        api_key = os.getenv('GEMINI_API_KEY')
        if not api_key:
            raise ValueError("GEMINI_API_KEY environment variable is not set.")
        self.client = genai.Client(api_key=api_key)
        
        # run_config parameters
        self.model_name = model_name
        self.top_k = 40
        self.top_p = 0.95
        self.temperature = 0.6
        self.thinking_budget = 8196
        self.max_output_tokens = 8192
        
        self.safety_settings = [
            types.SafetySetting(category="HARM_CATEGORY_HATE_SPEECH", threshold="OFF"),
            types.SafetySetting(category="HARM_CATEGORY_DANGEROUS_CONTENT", threshold="OFF"),
            types.SafetySetting(category="HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold="OFF"),
            types.SafetySetting(category="HARM_CATEGORY_HARASSMENT", threshold="OFF")
        ]
        
        self.system_prompt = SYSTEM_PROMPT

    def generate_response(self, request_text) -> dict:
        contents = [types.Content(role="user", parts=[request_text])]
        
        generate_content_config = types.GenerateContentConfig(
            temperature=self.temperature,
            top_p=self.top_p,
            top_k=self.top_k,
            max_output_tokens=self.max_output_tokens,
            safety_settings=self.safety_settings,
            system_instruction=[types.Part.from_text(text=self.system_prompt)],
            thinking_config=types.ThinkingConfig(
                thinking_budget=self.thinking_budget,
                include_thoughts=True,
            ),
        )

        output_text = ""
        thought_summary = ""
        try:
            for chunk in self.client.models.generate_content_stream(
                model=self.model_name,
                contents=contents,
                config=generate_content_config,
            ):
                if chunk.text is not None:
                    output_text += chunk.text
                if hasattr(chunk, "candidates") and chunk.candidates:
                    for candidate in chunk.candidates:
                        if hasattr(candidate, "content") and candidate.content and getattr(candidate.content, "parts", None):
                            for part in candidate.content.parts:
                                if getattr(part, "thought", False) and getattr(part, "text", None):
                                    thought_summary = (thought_summary + part.text) if thought_summary else part.text
        except Exception as e:
            raise e

        if thought_summary:
            print("\n" + "-" * 80)
            print("CHECKER THOUGHT SUMMARY:")
            print("-" * 80)
            print(thought_summary.strip())
            print("-" * 80 + "\n")
        
        if not output_text or not output_text.strip():
            raise ValueError("Empty response from model.")
        
        try:
            if "```json" in output_text:
                json_start = output_text.find("```json") + 7
                json_end = output_text.find("```", json_start)
                if json_end != -1:
                    output_text = output_text[json_start:json_end].strip()
            elif "```" in output_text:
                json_start = output_text.find("```") + 3
                json_end = output_text.find("```", json_start)
                if json_end != -1:
                    output_text = output_text[json_start:json_end].strip()
            
            parsed = json.loads(output_text.strip())
            return parsed
        except json.JSONDecodeError as e:
            raise ValueError(f"Failed to parse JSON response: {e}")

def _run_test_with_logging(creation_request: str, input_info: Optional[str] = None, generated_code: str = "", execution_result: str = "", past_review_outcomes: Optional[list] = None, checker: Optional[CheckCreateBudgetOrGoalOptimizer] = None):
    if checker is None:
        checker = CheckCreateBudgetOrGoalOptimizer()
    
    past_review_section = ""
    if past_review_outcomes:
        for index, past_review_outcome in enumerate(past_review_outcomes):
            past_review_section += f"""<PAST_REVIEW_OUTCOME_{index + 1}>
## Generated Code for #{index + 1}
```python
{past_review_outcome['generated_code']}
```
## Execution Result for #{index + 1}
{past_review_outcome['execution_result']}
## Evaluation Output for #{index + 1}
```json
{json.dumps(past_review_outcome['output'], indent=2)}
```
</PAST_REVIEW_OUTCOME_{index + 1}>
"""
    
    input_info_section = f"**Input Info from previous skill**: {input_info}" if input_info else "**Input Info from previous skill**: None"

    if not generated_code.startswith("def"):
        generated_code_block = f"```python\n{generated_code}\n```"
    else:
        generated_code_block = generated_code

    request_str = f"""<EVAL_INPUT>
**Last User Request**: {creation_request}
{input_info_section}
</EVAL_INPUT>

<GENERATED_CODE>
{generated_code_block}
</GENERATED_CODE>

<EXECUTION_RESULT>
{execution_result}
</EXECUTION_RESULT>

{past_review_section}

Output:"""
    
    print("=" * 80)
    print("LLM INPUT:")
    print("=" * 80)
    print(request_str)
    print("=" * 80)
    
    try:
        result = checker.generate_response(types.Part.from_text(text=request_str))
        print("LLM OUTPUT:")
        print(json.dumps(result, indent=2))
        return result
    except Exception as e:
        print(f"ERROR: {str(e)}")
        return None

def test_batch_1(checker: CheckCreateBudgetOrGoalOptimizer = None):
    # Topic: Multiple goals, one missing info.
    # Accuracy: generated_code creates one goal but should have asked for info for both.
    creation_request = "Set a $500 monthly budget for groceries and also start a savings goal for my new car."
    input_info = "Today is 2026-02-20."
    
    generated_code = """def process_input():
    success, result = create_category_spending_limit(
        category="meals_groceries",
        granularity="monthly",
        amount=500.0,
        title="Grocery Budget üõí"
    )
    return success, result"""

    execution_result = """create_category_spending_limit:
  category: "meals_groceries", amount: 500.0
  return: (True, "Grocery budget set.")
process_input:
True
Grocery budget set."""

    return _run_test_with_logging(creation_request, input_info, generated_code, execution_result, None, checker)

def test_batch_2(checker: CheckCreateBudgetOrGoalOptimizer = None):
    # Topic: Category specificity and missing granularity.
    # Accuracy: generated_code fails to ask for confirmation.
    creation_request = "I want to set a $100 budget for my Netflix and Spotify subscriptions."
    input_info = None
    
    generated_code = """def process_input():
    success, result = create_category_spending_limit(
        category="bills_connectivity",
        granularity="monthly",
        amount=100.0,
        title="Streaming Services üì∫"
    )
    return success, result"""

    execution_result = """create_category_spending_limit:
  category: "bills_connectivity", amount: 100.0
  return: (True, "Budget set.")
process_input:
True
Budget set."""

    return _run_test_with_logging(creation_request, input_info, generated_code, execution_result, None, checker)

def test_batch_3(checker: CheckCreateBudgetOrGoalOptimizer = None):
    # Topic: Amount computation and rounding up end_date.
    # Accuracy: generated_code rounds down instead of up.
    creation_request = "Save for a $1,500 vacation. I can put away $400 every week."
    input_info = "Today is 2026-02-20."
    
    # 1500 / 400 = 3.75 weeks. Should round up to 4 weeks.
    # 2026-02-20 + 4 weeks = 2026-03-20.
    # Generated code uses 3 weeks (2026-03-13).
    generated_code = """def process_input():
    # 3.75 weeks rounded down to 3 weeks (Incorrect)
    end_date = "2026-03-13" 
    success, result = create_savings_goal(
        amount=1500.0,
        end_date=end_date,
        goal_type="save_X_amount",
        title="Vacation Fund üèñÔ∏è"
    )
    return success, result"""

    execution_result = """create_savings_goal:
  amount: 1500.0, end_date: "2026-03-13"
  return: (True, "Goal created.")
process_input:
True
Goal created."""

    return _run_test_with_logging(creation_request, input_info, generated_code, execution_result, None, checker)

def test_batch_4(checker: CheckCreateBudgetOrGoalOptimizer = None):
    # Topic: Account IDs storage account check.
    # Accuracy: generated_code uses wrong account ID.
    creation_request = "I want to save $2,000 for my emergency fund in my High Yield Savings account."
    input_info = """Account 'Main Checking' (id: 123) | Balance: $5,000
Account 'High Yield Savings' (id: 456) | Balance: $1,000"""
    
    # Generated code uses Checking account (123) instead of Savings (456)
    generated_code = """def process_input():
    success, result = create_savings_goal(
        amount=2000.0,
        account_ids=[123], # Incorrect: should be 456
        goal_type="save_X_amount",
        title="Emergency Fund üõ°Ô∏è"
    )
    return success, result"""

    execution_result = """create_savings_goal:
  amount: 2000.0, account_ids: [123]
  return: (True, "Goal created.")
process_input:
True
Goal created."""

    return _run_test_with_logging(creation_request, input_info, generated_code, execution_result, None, checker)

def main(batch: int = 1):
    print(f"Testing CheckCreateBudgetOrGoalOptimizer - Batch {batch}\\n")
    checker = CheckCreateBudgetOrGoalOptimizer()
    
    if batch == 1:
        test_batch_1(checker)
    elif batch == 2:
        test_batch_2(checker)
    elif batch == 3:
        test_batch_3(checker)
    elif batch == 4:
        test_batch_4(checker)
    print("\\n")

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description='Run tests in batches')
    parser.add_argument('--batch', type=int, default=1, choices=[1, 2, 3, 4],
                        help='Batch number to run (1, 2, 3, or 4)')
    args = parser.parse_args()
    main(batch=args.batch)
